name: Deploy goodquestions to EC2

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    concurrency:
      group: goodquestions-main
      cancel-in-progress: true
    permissions:
      contents: read

    env:
      # NEW: your current VM
      REMOTE_HOST: ec2-18-184-17-18.eu-central-1.compute.amazonaws.com
      REMOTE_USER: ubuntu

      # NEW: folder layout on the VM for this project
      REMOTE_ROOT: /home/ubuntu/goodquestions
      REMOTE_DATA_DIR: /var/lib/goodquestions
      REMOTE_BACKUP_DIR: /var/backups/goodquestions

      # NEW: systemd service & API port for this app
      REMOTE_SERVICE: goodquestions
      SSH_PORT: "22"
      API_PORT: "3001"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node (for client build)
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: npm
          cache-dependency-path: client/package-lock.json

      - name: Build client
        working-directory: client
        env:
          NPM_CONFIG_AUDIT: "false"
          NPM_CONFIG_FUND: "false"
        run: |
          set -euo pipefail
          npm ci
          npm run build

      - name: Ensure target dirs on VM
        uses: appleboy/ssh-action@v1.2.2
        with:
          host:     ${{ env.REMOTE_HOST }}
          username: ${{ env.REMOTE_USER }}
          key:      ${{ secrets.EC2_SSH_KEY }}
          envs: REMOTE_ROOT,REMOTE_DATA_DIR,REMOTE_BACKUP_DIR
          script: |
            set -euo pipefail
            sudo mkdir -p "$REMOTE_DATA_DIR" "$REMOTE_BACKUP_DIR"
            sudo chown -R "$USER":"$USER" "$REMOTE_DATA_DIR" "$REMOTE_BACKUP_DIR"
            mkdir -p "$REMOTE_ROOT/client/dist"
            mkdir -p "$REMOTE_ROOT/server"

      - name: Deploy client build (rsync over SSH:22)
        uses: easingthemes/ssh-deploy@v5.1.0
        env:
          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          REMOTE_HOST:      ${{ env.REMOTE_HOST }}
          REMOTE_USER:      ${{ env.REMOTE_USER }}
          REMOTE_PORT:      ${{ env.SSH_PORT }}
          ARGS:             "-avzr --delete"
          SOURCE:           "client/dist/"
          TARGET:           "${{ env.REMOTE_ROOT }}/client/dist"

      # Deploy backend code (keeps secrets/DB on VM)
      - name: Deploy server code
        uses: easingthemes/ssh-deploy@v5.1.0
        env:
          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
          REMOTE_HOST:      ${{ env.REMOTE_HOST }}
          REMOTE_USER:      ${{ env.REMOTE_USER }}
          REMOTE_PORT:      ${{ env.SSH_PORT }}
          ARGS: >-
            -avzr --delete
            --exclude='.git'
            --exclude='node_modules'
            --exclude='.env'
            --exclude='*.sqlite'
            --exclude='data/'
          SOURCE:           "server/"
          TARGET:           "${{ env.REMOTE_ROOT }}/server"

      - name: Post-deploy (install deps, optional migrate, restart; reload Caddy)
        uses: appleboy/ssh-action@v1.2.2
        with:
          host:     ${{ env.REMOTE_HOST }}
          username: ${{ env.REMOTE_USER }}
          key:      ${{ secrets.EC2_SSH_KEY }}
          envs: REMOTE_ROOT,REMOTE_DATA_DIR,REMOTE_BACKUP_DIR,REMOTE_SERVICE,API_PORT
          script: |
            set -euo pipefail
            cd "$REMOTE_ROOT/server"
            NODE_ENV=production npm ci --omit=dev --no-audit --no-fund

            # Use dedicated prod DB path on VM
            export DB_PATH="${REMOTE_DATA_DIR}/prod.sqlite"
            mkdir -p "${REMOTE_DATA_DIR}" "${REMOTE_BACKUP_DIR}"

            # One-time migrate old DB if it exists under server/
            if [ -f "$REMOTE_ROOT/server/asa.db" ] && [ ! -f "$DB_PATH" ]; then
              echo "Moving legacy DB server/asa.db to ${DB_PATH}..."
              mv "$REMOTE_ROOT/server/asa.db" "$DB_PATH"
            fi

            # Backup if DB exists
            if [ -f "$DB_PATH" ]; then
              ts=$(date -u +%Y%m%d_%H%M%S)
              cp -a "$DB_PATH" "${REMOTE_BACKUP_DIR}/prod.${ts}.sqlite"
              echo "Backed up DB to ${REMOTE_BACKUP_DIR}/prod.${ts}.sqlite"
            fi

            # Run migrations if your repo has them (safe to skip if not present)
            if [ -f "./migrate.js" ]; then
              env DB_PATH="$DB_PATH" MIGRATIONS_DIR="$REMOTE_ROOT/server/migrations" node ./migrate.js || true
            fi

            sudo systemctl restart "$REMOTE_SERVICE"

            # Health check
            for i in $(seq 1 60); do
              if sudo ss -ltnp | grep -q ":${API_PORT}"; then
                code=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout 2 "http://127.0.0.1:${API_PORT}/" || true)
                if echo "$code" | grep -Eq '^(200|30[12]|401)$'; then
                  echo "Backend healthy (HTTP $code)"; break
                fi
              fi
              [ "$i" -eq 60 ] && { echo "Backend not healthy"; sudo journalctl -u "$REMOTE_SERVICE" -n 200 --no-pager || true; exit 1; }
              sleep 1
            done

            # Reload Caddy (if present)
            sudo systemctl reload caddy || true

            echo "${{ github.sha }}" | sudo tee "${REMOTE_ROOT}/.deployed_sha" >/dev/null
            date -u | sudo tee "${REMOTE_ROOT}/.deployed_at" >/dev/null
